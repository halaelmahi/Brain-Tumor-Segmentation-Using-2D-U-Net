# -*- coding: utf-8 -*-
"""BrainTumor_Segmentation_Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bqj4WGJ5RBvI2Siz-wgloVr-gI9_vdY-
"""

from google.colab import drive
drive.mount('/content/drive')
print("‚úÖ Drive mounted")

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/archive/project_root
!ls -1
print("‚úÖ In project_root")

!pip install -q nibabel SimpleITK h5py scikit-learn matplotlib numpy scipy tqdm
print("‚úÖ Libraries ready")

# Commented out IPython magic to ensure Python compatibility.
# ‚ñ∂Ô∏è 1.  Go to your project folder (the one that contains src/)
# %cd /content/drive/MyDrive/archive/project_root

# ‚ñ∂Ô∏è 2.  Run training on GPU
!env PYTHONPATH="$PWD" \
  python src/train.py \
    --data_dir data \
    --results_dir results_gpu_demo \
    --epochs 1 \
    --batch_size 2 \
    --lr 1e-3

# üîç Cell A ‚Äì search for every .pth file under project_root
!find /content/drive/MyDrive/archive/project_root -type f -name "*.pth" | sed 's/^/‚Üí /'

# Commented out IPython magic to ensure Python compatibility.
# üö© run this *once* in a new cell, BEFORE the evaluation cell
# %cd /content/drive/MyDrive/archive/project_root

# ==== evaluation cell ====
import os, sys, torch, numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# ------------------------------------------------------------------
# 1Ô∏è‚É£  make sure Python can import "src.*"
proj_root = Path.cwd()                    # expecting .../archive/project_root
if str(proj_root) not in sys.path:
    sys.path.insert(0, str(proj_root))    # same effect as PYTHONPATH
print("PYTHONPATH ok ‚Üí", proj_root)

# ------------------------------------------------------------------
# 2Ô∏è‚É£  fixed imports
from src.dataset import BraTSSliceDataset
from src.model   import UNet2D

# ------------------------------------------------------------------
# 3Ô∏è‚É£  paths & device
data_dir   = proj_root / "data"
ckpt_path  = proj_root / "results_gpu_demo" / "best_model.pth"  # adjust if you used a different folder
assert ckpt_path.exists(), f"checkpoint missing: {ckpt_path}"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("üëâ device:", device)

# ------------------------------------------------------------------
# 4Ô∏è‚É£  dataset & loader (no augmentation)
ds      = BraTSSliceDataset(str(data_dir))
loader  = torch.utils.data.DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)

# ------------------------------------------------------------------
# 5Ô∏è‚É£  model, load weights
model = UNet2D(in_channels=4, out_channels=3).to(device)
model.load_state_dict(torch.load(ckpt_path, map_location=device))
model.eval()
print("‚úÖ checkpoint loaded")

# ------------------------------------------------------------------
# 6Ô∏è‚É£  optional quick overlay helper -------------
def quick_overlay(img4ch, mask, pred, out_path):
    """save a simple 3-panel overlay PNG"""
    t1 = img4ch[0]        # first channel as grayscale
    plt.figure(figsize=(6,3))
    plt.subplot(1,3,1); plt.imshow(t1, cmap='gray');  plt.title('T1'); plt.axis('off')
    plt.subplot(1,3,2); plt.imshow(mask, cmap='Reds', alpha=.6); plt.title('GT');  plt.axis('off')
    plt.subplot(1,3,3); plt.imshow(pred, cmap='Blues', alpha=.6); plt.title('Pred');plt.axis('off')
    plt.tight_layout(); plt.savefig(out_path); plt.close()
# -----------------------------------------------

# ------------------------------------------------------------------
# 7Ô∏è‚É£  evaluation loop
dices = []
overlay_dir = proj_root / "results_gpu_demo" / "eval_overlays"
overlay_dir.mkdir(parents=True, exist_ok=True)

for i,(img, msk) in enumerate(loader):
    img, msk = img.to(device), msk.to(device)
    with torch.no_grad():
        logits = model(img)
        pred   = torch.argmax(torch.softmax(logits,1), dim=1)

    # Dice per slice (foreground vs background)
    inter = ((pred == msk) & (pred > 0)).sum().float()
    union = (pred > 0).sum() + (msk > 0).sum()
    dice  = (2*inter / union) if union > 0 else torch.tensor(1.0)
    dices.append(dice.item())

    # save first 10 overlays
    if i < 10:
        quick_overlay(img[0].cpu(), msk[0].cpu(), pred[0].cpu(),
                      overlay_dir / f"overlay_{i}.png")

print(f"üèÅ  evaluated {len(dices)} slices  |  mean Dice = {np.mean(dices):.3f}")
print(f"Overlay PNGs saved to: {overlay_dir}")

import glob, random, os
from IPython.display import Image, display

overlay_dir = "/content/drive/MyDrive/archive/project_root/results_gpu_demo/eval_overlays"
pngs = glob.glob(os.path.join(overlay_dir, "overlay_*.png"))
print(f"‚úÖ found {len(pngs)} overlay PNG(s)")

if not pngs:
    print("‚ö†Ô∏è  No overlays saved‚Äîcheck that plot_overlay was called in evaluation.")
else:
    # choose up to 4 without error
    for path in random.sample(pngs, k=min(4, len(pngs))):
        display(Image(path))

# list every results folder under your project_root
!find /content/drive/MyDrive/archive/project_root -maxdepth 2 -type d -name "results*" | sed 's/^/‚Üí /'

# from /content/drive/MyDrive/archive/project_root
!find results_gpu_demo -maxdepth 1 -type f -name "*.pth" | sed 's/^/‚Üí /'

# Commented out IPython magic to ensure Python compatibility.
# ‚îÄ‚îÄ Cell X ‚îÄ‚îÄ
# %cd /content/drive/MyDrive/archive/project_root
!find results_gpu_demo -maxdepth 1 -type f -name "*.pth" | sed 's/^/‚Üí /'

# Commented out IPython magic to ensure Python compatibility.
# ‚îÄ‚îÄ Cell Y ‚îÄ‚îÄ
# %cd /content/drive/MyDrive/archive/project_root
!find . -type f -name "*.pth" | sed 's/^/‚Üí /'

from src.utils import soft_dice_loss

import torch
from torch.utils.data import DataLoader
from src.dataset import BraTSSliceDataset
from src.model   import UNet2D
from src.utils   import soft_dice_loss

# 1Ô∏è‚É£ Setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# 2Ô∏è‚É£ Load one sample
ds = BraTSSliceDataset("data")      # adjust the path if needed
img, msk = ds[0]                    # (4,H,W), (H,W)
img = img.unsqueeze(0).to(device)   # (1,4,H,W)
msk = msk.unsqueeze(0).to(device)   # (1,H,W)

# 3Ô∏è‚É£ Load model
model = UNet2D(in_channels=4, out_channels=3).to(device)
ckpt = "results_gpu_demo/best_model.pth"   # path to your checkpoint
print("Loading checkpoint from", ckpt)
state = torch.load(ckpt, map_location=device)
model.load_state_dict(state)
model.eval()

# 4Ô∏è‚É£ Forward & Dice
with torch.no_grad():
    logits = model(img)                          # (1,3,H,W)
    probs  = torch.softmax(logits, dim=1)        # (1,3,H,W)
    dice   = 1.0 - soft_dice_loss(probs, msk)    # scalar
print(f"Slice Dice = {dice.item():.4f}")

import matplotlib.pyplot as plt
import numpy as np

# we assume img, msk, probs are still in scope from the previous cell:
# img: (1,4,H,W), msk: (1,H,W), probs: (1,3,H,W)

# pick modality 0 for display
input_slice = img.cpu().numpy()[0,0]       # (H,W)
gt_mask     = msk.cpu().numpy()[0]         # (H,W)
pred_mask   = probs.argmax(1).cpu().numpy()[0]  # (H,W)

# 1Ô∏è‚É£ Show side-by-side
fig, axes = plt.subplots(1,3, figsize=(15,5))
axes[0].imshow(input_slice, cmap='gray')
axes[0].set_title('Input (modality 0)')
axes[1].imshow(input_slice, cmap='gray')
axes[1].imshow(gt_mask,   cmap='jet', alpha=0.5)
axes[1].set_title('Ground Truth')
axes[2].imshow(input_slice, cmap='gray')
axes[2].imshow(pred_mask,  cmap='jet', alpha=0.5)
axes[2].set_title('Prediction')
for ax in axes: ax.axis('off')
plt.show()

# 2Ô∏è‚É£ Overlay contours (GT=red, Pred=green)
fig, ax = plt.subplots(figsize=(6,6))
ax.imshow(input_slice, cmap='gray')
ax.contour(gt_mask,   colors='r', linewidths=1)
ax.contour(pred_mask, colors='g', linewidths=1)
ax.set_title('GT (red) vs Pred (green)')
ax.axis('off')
plt.show()

# ‚îÄ‚îÄ Cell X: recompute per‚Äêslice Dice scores ‚îÄ‚îÄ
import os, torch, numpy as np
from torch.utils.data import DataLoader
from src.dataset import BraTSSliceDataset
from src.model   import UNet2D
from src.utils   import soft_dice_loss

# 1Ô∏è‚É£ set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 2Ô∏è‚É£ load model checkpoint
ckpt_path = "results_gpu_demo/best_model.pth"
model = UNet2D(in_channels=4, out_channels=3).to(device)
model.load_state_dict(torch.load(ckpt_path, map_location=device))
model.eval()

# 3Ô∏è‚É£ prepare slice‚Äêdataset & loader
ds     = BraTSSliceDataset("data/")
loader = DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)

# 4Ô∏è‚É£ compute Dice per slice
dices = []
with torch.no_grad():
    for img, msk in loader:
        img, msk = img.to(device), msk.to(device)
        logits = model(img)
        dice   = 1.0 - soft_dice_loss(torch.softmax(logits,1), msk)
        dices.append(dice.item())

print(f"‚úî Computed {len(dices)} slice Dice scores (mean = {np.mean(dices):.3f})")

# ‚îÄ‚îÄ Cell Y: plot Dice distribution ‚îÄ‚îÄ
import matplotlib.pyplot as plt
import numpy as np

plt.figure(figsize=(6,4))
plt.hist(dices, bins=50, edgecolor='k', alpha=0.7)
plt.xlabel("Slice‚Äêlevel Dice")
plt.ylabel("Number of slices")
plt.title(f"Dice Distribution (mean = {np.mean(dices):.3f})")
plt.axvline(np.mean(dices), color='r', linestyle='--', label='Mean')
plt.legend()
plt.tight_layout()
plt.show()

# ‚îÄ‚îÄ Cell Z: per-class Dice & save histogram ‚îÄ‚îÄ
import torch, numpy as np
import matplotlib.pyplot as plt

# 1Ô∏è‚É£ compute class-wise Dice
# assumes: loader, model, device, soft_dice_loss already defined from evaluation cell
class_dices = {1: [], 2: [], 3: []}
model.eval()
with torch.no_grad():
    for img, msk in loader:
        img, msk = img.to(device), msk.to(device)
        logits = model(img)
        preds  = torch.argmax(torch.softmax(logits,1), dim=1)
        for cls in class_dices:
            inter = ((preds == cls) & (msk == cls)).sum().float()
            union = (preds == cls).sum() + (msk == cls).sum()
            dice  = (2*inter/union) if union>0 else torch.tensor(1.0)
            class_dices[cls].append(dice.item())

# 2Ô∏è‚É£ print per-class means
for cls, scores in class_dices.items():
    print(f"Class {cls} mean Dice: {np.mean(scores):.3f}")

# 3Ô∏è‚É£ re-plot & save overall histogram
plt.figure(figsize=(6,4))
plt.hist(dices, bins=50, edgecolor='k', alpha=0.7)
mean_d = np.mean(dices)
plt.axvline(mean_d, color='r', linestyle='--', label=f"Mean = {mean_d:.3f}")
plt.title("Slice-level Dice Distribution")
plt.xlabel("Dice")
plt.ylabel("Number of slices")
plt.legend()
plt.tight_layout()
plt.savefig("dice_distribution.png", dpi=300)   # saved for your slide
plt.show()

# ‚îÄ‚îÄ Cell Z+1: quick display of 4 example overlays ‚îÄ‚îÄ
import matplotlib.pyplot as plt
import glob
import os

# adjust if you used a different eval_overlays path
overlay_dir = "/content/drive/MyDrive/archive/project_root/results_gpu_demo/eval_overlays"

# grab up to four overlay PNGs
pngs = sorted(glob.glob(os.path.join(overlay_dir, "overlay_*.png")))
pngs = pngs[:4]

# plot in a 2√ó2 grid
fig, axes = plt.subplots(2, 2, figsize=(10,10))
for ax, path in zip(axes.flatten(), pngs):
    img = plt.imread(path)
    ax.imshow(img)
    ax.set_title(os.path.basename(path))
    ax.axis("off")

plt.tight_layout()
plt.show()

# ‚îÄ‚îÄ Cell Z+2 (20-epoch train/val + checkpoint + metric logging) ‚îÄ‚îÄ
import torch
import torch.nn.functional as F
from torch.utils.data import random_split, DataLoader
from torchvision import transforms
from src.dataset import BraTSSliceDataset
from src.model   import UNet2D
from src.utils   import soft_dice_loss

# 1Ô∏è‚É£ prepare datasets & loaders
full_ds = BraTSSliceDataset("data",
    transform=transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.RandomRotation(15),
    ]))
n       = len(full_ds)
n_train = int(0.8 * n)
train_ds, val_ds = random_split(full_ds, [n_train, n - n_train],
                                generator=torch.Generator().manual_seed(42))

train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,
                          num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=2, shuffle=False,
                          num_workers=2, pin_memory=True)

# 2Ô∏è‚É£ model, optimizer, device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model  = UNet2D(in_channels=4, out_channels=3).to(device)
opt    = torch.optim.AdamW(model.parameters(), lr=1e-3)

# 3Ô∏è‚É£ training loop (20 epochs)
best_val_dice = 0.0
train_losses, train_dices, val_dices = [], [], []

for epoch in range(1, 21):   # ‚Üê now 1..20
    # ‚Äî training ‚Äî
    model.train()
    running_loss, running_dice = 0.0, 0.0
    for imgs, masks in train_loader:
        imgs, masks = imgs.to(device), masks.to(device)
        opt.zero_grad()
        logits = model(imgs)
        ce     = F.cross_entropy(logits, masks)
        sdice  = soft_dice_loss(torch.softmax(logits,1), masks)
        loss   = ce + sdice
        loss.backward()
        opt.step()

        running_loss += loss.item() * imgs.size(0)
        with torch.no_grad():
            pred  = torch.argmax(torch.softmax(logits,1), dim=1)
            inter = ((pred == masks) & (pred > 0)).sum().float()
            union = (pred > 0).sum() + (masks > 0).sum()
            running_dice += ((2*inter/union) if union>0 else torch.tensor(1.0)).item() * imgs.size(0)

    avg_loss = running_loss / n_train
    avg_dice = running_dice / n_train
    train_losses.append(avg_loss)
    train_dices.append(avg_dice)

    # ‚Äî validation ‚Äî
    model.eval()
    val_dice = 0.0
    with torch.no_grad():
        for imgs, masks in val_loader:
            imgs, masks = imgs.to(device), masks.to(device)
            logits = model(imgs)
            pred   = torch.argmax(torch.softmax(logits,1), dim=1)
            inter  = ((pred == masks) & (pred > 0)).sum().float()
            union  = (pred > 0).sum() + (masks > 0).sum()
            val_dice += ((2*inter/union) if union>0 else torch.tensor(1.0)).item() * imgs.size(0)

    val_dice /= (n - n_train)
    val_dices.append(val_dice)

    print(f"Epoch {epoch:02d} | Train loss {avg_loss:.3f} | "
          f"Train Dice {avg_dice:.3f} | Val Dice {val_dice:.3f}")

    # ‚Äî checkpoint if improved ‚Äî
    if val_dice > best_val_dice:
        best_val_dice = val_dice
        torch.save(model.state_dict(), "best_fulltrain_model.pth")
        print(f"  ‚Üí New best val Dice: {best_val_dice:.3f}, checkpoint saved.")

print("‚ñ∫ Training complete. Best Val Dice:", best_val_dice)

# ‚îÄ‚îÄ Cell Z+3: plot & save training history ‚îÄ‚îÄ
import matplotlib.pyplot as plt

# epochs 1..N
epochs = range(1, len(train_dices) + 1)

# Plot Dice curves
plt.figure(figsize=(6,4))
plt.plot(epochs, train_dices, '-o', label="Train Dice")
plt.plot(epochs, val_dices,   '-o', label="Val Dice")
plt.xlabel("Epoch")
plt.ylabel("Dice")
plt.title("Train vs Val Dice over Epochs")
plt.legend()
plt.tight_layout()
plt.savefig("dice_curves.png", dpi=300)
plt.show()

# Plot Loss curve
plt.figure(figsize=(6,4))
plt.plot(epochs, train_losses, '-o', label="Train Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss over Epochs")
plt.legend()
plt.tight_layout()
plt.savefig("loss_curve.png", dpi=300)
plt.show()

# ‚îÄ‚îÄ Cell Z+4: Final evaluation on best_fulltrain_model.pth ‚îÄ‚îÄ
import os, sys, torch, numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from src.dataset import BraTSSliceDataset
from src.model   import UNet2D

# 1Ô∏è‚É£ Ensure project root is on PYTHONPATH
proj_root = Path.cwd()
if str(proj_root) not in sys.path:
    sys.path.insert(0, str(proj_root))

# 2Ô∏è‚É£ Set paths & device
ckpt_path  = proj_root / "best_fulltrain_model.pth"
data_dir   = proj_root / "data"
overlay_dir = proj_root / "eval_overlays"
overlay_dir.mkdir(exist_ok=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# 3Ô∏è‚É£ Prepare dataset & loader
ds     = BraTSSliceDataset(str(data_dir))
loader = torch.utils.data.DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)

# 4Ô∏è‚É£ Load model
model = UNet2D(in_channels=4, out_channels=3).to(device)
model.load_state_dict(torch.load(ckpt_path, map_location=device))
model.eval()
print("Loaded checkpoint:", ckpt_path.name)

# 5Ô∏è‚É£ Helper to save overlay
def quick_overlay(img4ch, mask, pred, out_path):
    t1 = img4ch[0]
    plt.figure(figsize=(6,3))
    plt.subplot(1,3,1); plt.imshow(t1, cmap='gray');  plt.axis('off')
    plt.subplot(1,3,2); plt.imshow(mask, cmap='Reds', alpha=.6);  plt.axis('off')
    plt.subplot(1,3,3); plt.imshow(pred, cmap='Blues', alpha=.6); plt.axis('off')
    plt.tight_layout(); plt.savefig(out_path); plt.close()

# 6Ô∏è‚É£ Run evaluation
slice_dices = []
class_dices = {1: [], 2: [], 3: []}

for idx, (img, msk) in enumerate(loader):
    img, msk = img.to(device), msk.to(device)
    with torch.no_grad():
        logits = model(img)
        pred   = torch.argmax(torch.softmax(logits,1), dim=1)

    # slice-level Dice (foreground vs background)
    inter = ((pred == msk) & (pred > 0)).sum().float()
    union = (pred > 0).sum() + (msk > 0).sum()
    dice  = (2*inter/union) if union>0 else torch.tensor(1.0)
    slice_dices.append(dice.item())

    # per-class Dice
    for cls in class_dices:
        inter_c = ((pred==cls) & (msk==cls)).sum().float()
        union_c = (pred==cls).sum() + (msk==cls).sum()
        class_dices[cls].append(((2*inter_c/union_c) if union_c>0 else torch.tensor(1.0)).item())

    # save first 10 overlays
    if idx < 10:
        quick_overlay(img[0].cpu(), msk[0].cpu(), pred[0].cpu(),
                      overlay_dir/f"overlay_{idx}.png")

# 7Ô∏è‚É£ Report results
print(f"Evaluated {len(slice_dices)} slices | Mean slice Dice = {np.mean(slice_dices):.3f}")
for cls, scores in class_dices.items():
    print(f"Class {cls} mean Dice = {np.mean(scores):.3f}")

# 8Ô∏è‚É£ Plot histogram
plt.figure(figsize=(6,4))
plt.hist(slice_dices, bins=50, edgecolor='k', alpha=0.7)
plt.axvline(np.mean(slice_dices), linestyle='--', label=f"Mean = {np.mean(slice_dices):.3f}")
plt.title("Slice-level Dice Distribution")
plt.xlabel("Dice"); plt.ylabel("Count"); plt.legend()
plt.tight_layout()
plt.savefig("slice_dice_hist.png", dpi=300)
plt.show()

# 9Ô∏è‚É£ Display overlays
import glob
from IPython.display import Image, display
pngs = sorted(glob.glob(str(overlay_dir/"overlay_*.png")))[:4]
fig, axes = plt.subplots(1,4, figsize=(16,4))
for ax, p in zip(axes, pngs):
    img = plt.imread(p)
    ax.imshow(img); ax.axis("off")
plt.tight_layout()
plt.show()

# ‚îÄ‚îÄ Cell Z+5: Compute patient-level (volume-wise) Dice ‚îÄ‚îÄ
import glob
import numpy as np
from collections import defaultdict
from pathlib import Path

# 1Ô∏è‚É£ Gather all .h5 file paths in sorted order
h5_paths = sorted(glob.glob(str(data_dir/"*.h5")))

# 2Ô∏è‚É£ Prepare a dict to collect slice Dices per volume
vol_slice_dices = defaultdict(list)

# 3Ô∏è‚É£ Re-use your model & loader (must match the same order as h5_paths)
model.eval()
with torch.no_grad():
    for path, (img, msk) in zip(h5_paths, loader):
        img, msk = img.to(device), msk.to(device)
        logits = model(img)
        pred   = torch.argmax(torch.softmax(logits,1), dim=1)
        # compute slice Dice (foreground vs background)
        inter = ((pred == msk) & (pred > 0)).sum().float()
        union = (pred > 0).sum() + (msk > 0).sum()
        slice_dice = (2*inter/union).item() if union>0 else 1.0

        # extract volume ID (everything before "_slice_")
        vol_id = Path(path).stem.split("_slice_")[0]
        vol_slice_dices[vol_id].append(slice_dice)

# 4Ô∏è‚É£ Compute mean Dice per volume
vol_mean_dice = {vol: np.mean(dices) for vol, dices in vol_slice_dices.items()}

# 5Ô∏è‚É£ Report overall stats
all_vol_dices = np.array(list(vol_mean_dice.values()))
print(f"Evaluated {len(vol_mean_dice)} volumes")
print(f"Mean volume-level Dice: {all_vol_dices.mean():.3f}")
print(f"Std  volume-level Dice: {all_vol_dices.std():.3f}")

# 6Ô∏è‚É£ List top 5 & bottom 5 volumes by Dice
sorted_vols = sorted(vol_mean_dice.items(), key=lambda x: x[1])
print("\nBottom 5 volumes:")
for vol, dice in sorted_vols[:5]:
    print(f"  {vol}: {dice:.3f}")
print("\nTop 5 volumes:")
for vol, dice in sorted_vols[-5:]:
    print(f"  {vol}: {dice:.3f}")

# ‚îÄ‚îÄ Cell Z+6: Export predicted volumes as NIfTI files ‚îÄ‚îÄ
import glob
import h5py
import numpy as np
import nibabel as nib
from pathlib import Path

# paths
data_dir      = Path("data")
overlay_dir   = Path("eval_overlays")
output_dir    = Path("volume_predictions")
output_dir.mkdir(exist_ok=True)

# gather h5 paths and group by volume
h5_paths = sorted(glob.glob(str(data_dir/"volume_*_slice_*.h5")))
vol_slices = {}
for p in h5_paths:
    stem = Path(p).stem               # e.g. volume_224_slice_68
    vol, _, slice_idx = stem.rpartition("_slice_")
    idx = int(slice_idx)
    vol_slices.setdefault(vol, []).append((idx, p))

# iterate volumes
model.eval()
with torch.no_grad():
    for vol, slice_list in vol_slices.items():
        # sort slices
        slice_list.sort(key=lambda x: x[0])
        preds = []
        for idx, h5_path in slice_list:
            # load image
            with h5py.File(h5_path, "r") as f:
                img4 = f["image"][()]      # shape (4,H,W)
            # prepare tensor
            img_tensor = torch.from_numpy(img4[np.newaxis]).to(device)  # (1,4,H,W)
            # predict
            logits = model(img_tensor)
            pred   = torch.argmax(torch.softmax(logits,1), dim=1).cpu().numpy()[0]  # (H,W)
            preds.append(pred)
        # stack into 3D (Z, H, W)
        vol_pred = np.stack(preds, axis=0)
        # save as NIfTI
        affine = np.eye(4)
        nii = nib.Nifti1Image(vol_pred.astype(np.uint8), affine)
        nib.save(nii, output_dir/f"{vol}_pred.nii.gz")
        print(f"Saved {vol}_pred.nii.gz")

# ‚îÄ‚îÄ Cell Z+7: Compute volume-level and class-wise 3D Dice from NIfTI outputs ‚îÄ‚îÄ
import glob
import h5py
import nibabel as nib
import numpy as np
from collections import defaultdict
from pathlib import Path

# paths
pred_dir = Path("volume_predictions")
data_dir = Path("data")

# collect prediction files
pred_files = sorted(pred_dir.glob("*_pred.nii.gz"))

# helper to load and stack GT masks for a given volume
def load_gt_volume(vol_id):
    # find all slices for this volume
    h5_paths = sorted(data_dir.glob(f"{vol_id}_slice_*.h5"), key=lambda p: int(p.stem.split("_slice_")[1]))
    masks = []
    for p in h5_paths:
        with h5py.File(p, "r") as f:
            masks.append(f["mask"][()])   # shape (H, W)
    return np.stack(masks, axis=0)     # shape (Z, H, W)

# store metrics
vol_dice = {}
class_dice = defaultdict(dict)

for pf in pred_files:
    vol_id = pf.stem.replace("_pred", "")
    # load prediction and GT
    pred_vol = nib.load(str(pf)).get_fdata().astype(int)       # (Z, H, W)
    gt_vol   = load_gt_volume(vol_id).astype(int)              # (Z, H, W)

    # overall (foreground vs background) Dice
    fg_pred = pred_vol > 0
    fg_gt   = gt_vol   > 0
    inter = np.logical_and(fg_pred, fg_gt).sum()
    union = fg_pred.sum() + fg_gt.sum()
    vol_dice[vol_id] = 2 * inter / union if union > 0 else 1.0

    # per-class Dice
    for cls in [1, 2, 3]:
        p_mask = pred_vol == cls
        g_mask = gt_vol   == cls
        inter_c = np.logical_and(p_mask, g_mask).sum()
        union_c = p_mask.sum() + g_mask.sum()
        class_dice[vol_id][cls] = 2 * inter_c / union_c if union_c > 0 else 1.0

# print summary
print("Volume-level Dice:")
for vol, d in vol_dice.items():
    print(f"  {vol}: {d:.3f}")

print("\nPer-class Dice by volume:")
for vol, scores in class_dice.items():
    print(f"  {vol}: Enhancing={scores[1]:.3f}, Edema={scores[2]:.3f}, Necrotic={scores[3]:.3f}")

# overall statistics
all_vols = np.array(list(vol_dice.values()))
print(f"\nMean volume Dice = {all_vols.mean():.3f}, Std = {all_vols.std():.3f}")

# ‚îÄ‚îÄ Cell Z+8: save metrics to CSV ‚îÄ‚îÄ
import pandas as pd

# assume you have:
#  slice_dices          ‚Äì list of per‚Äêslice Dice
#  class_dices          ‚Äì dict mapping class‚Üílist of per‚Äêslice Dice
#  vol_mean_dice        ‚Äì dict mapping vol_id‚Üímean volume Dice
#  class_dice_per_vol   ‚Äì dict mapping vol_id‚Üí{cls: Dice}

# 1Ô∏è‚É£ build slice‚Äêlevel DataFrame
slice_df = pd.DataFrame({
    "slice_index": range(len(slice_dices)),
    "slice_dice": slice_dices
})

# 2Ô∏è‚É£ build per‚Äêclass DataFrame
class_df = pd.DataFrame({
    "slice_index": range(len(slice_dices)),
    **{f"class_{cls}_dice": scores for cls, scores in class_dices.items()}
})

# 3Ô∏è‚É£ build volume‚Äêlevel DataFrame
vol_df = pd.DataFrame([
    {"vol_id": vol, "vol_dice": dice,
     **{f"class_{cls}_dice": class_dice_per_vol[vol][cls] for cls in [1,2,3]}}
    for vol, dice in vol_mean_dice.items()
])

# 4Ô∏è‚É£ write to disk
slice_df.to_csv("slice_metrics.csv", index=False)
class_df.to_csv("class_metrics.csv", index=False)
vol_df.to_csv("volume_metrics.csv", index=False)

print("‚úî Metrics exported: slice_metrics.csv, class_metrics.csv, volume_metrics.csv")

